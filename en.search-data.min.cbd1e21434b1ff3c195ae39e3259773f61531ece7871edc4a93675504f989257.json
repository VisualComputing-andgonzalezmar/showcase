[{"id":0,"href":"/showcase/docs/entrega2/3dUserInteraction/","title":"3d User Interaction","section":"Segunda Entrega","content":" 3D User Interaction # Introduccion # En el campo de la computacion, la interaccion 3D es una forma de intereaccion entre Humano y Maquina, donde los usuarios son capaces de moverse e interactuar en un espacio en tres dimensiones. Lo mas relevante es que ambas partes (Humano y Maquina) deben procesar la informacion de la posicion fisica de los elementos en el espacio tridimensional para lograr una perfecta interaccion.\nPara lograr esta interaccion se suele usar un dispositivo de entrada, que detecta los movimientos e interacciones del usuario para simular la escena y las acciones que se realizaron en un dispositivo de salida.\nProbando # Historia # Los primeros avances en la interaccion y visualizacion en 3D comenzó en la decada de 1960, por investigadores como Ivan Sutherland, Fred Brooks, Bob Sproull, Andrew Ortony y Richard Feldman. Sin embargo, no fue hasta 1962 cuando Morton Heilig inventó el simulador Sensorama, el cual proporcionó retroalimentación de video 3D, así como movimiento, audio y para producir un entorno virtual. La siguiente etapa de desarrollo fue la finalización del trabajo pionero de Ivan Sutherland en 1968, la Espada de Damocles, que invento una pantalla montada en la cabeza que producía un entorno virtual en 3D al presentar una imagen fija de izquierda y derecha de ese entorno.\nLa disponibilidad de la tecnología, así como los costos poco prácticos, frenaron el desarrollo y la aplicación de entornos virtuales hasta la década de 1980 y las aplicaciones se limitaron a empresas militares en los Estados Unidos. Desde entonces, más investigaciones y avances tecnológicos han permitido que se abran nuevas puertas para la aplicación en otras áreas, como la educación, el entretenimiento y la fabricación.\nSelection and Manipulation # Las tecnicas en este campo se basan principalmente en completar tres tareas basicas:\nSeleccionar un objeto Posicionar un objeto Rotar un objeto El usuario necesita de manera obligatoria la forma de manipular los objetos virtuales, donde estos puedan ser seleccionados para realizar dicha accion.\nSelection # Para realizar esta accion, el usuario primero debe encontrarse en la capacidad de ubicar el objeto deseado en el espacio mediante una correcta manipulacion de la vista en dicho espacio. Ya identificado el objeto, existen diversar formas y tecnicas para seleccionar el objeto.\nUna de las tecnicas de seleccion puede ser la interseccion del cursor, que nos permite interactuar en el espacio virtual, con algun objeto del entorno. Este cursor suele ser una simulacion de una mano humana, guiada por el dispositivo de entrada que se este usando.\nManipulation # Es una tarea que se realiza despues de realizar la seleccion del objeto, donde este es manipulado por el usuario segun las fisicas definidas. Se pueden realizar acciones como rotar, mover, acercar, etc.\nLa principal accion de manipulacion que debe permitir la aplicacion es la navegacion por el entorno virtual, dado que sin esta seria incapaz de ver por completo este espacio virtual y lograr interactuar de manera completa con los objetos en este.\nSystem Control # Finalmente cabe resaltar que se quiere de un sistema de control mediante el uso de dispositivos de entrada, que le permita al usuario realizar las acciones previamente descritas. Podemos agrupar estos sistemas en 4 grandes categorias, que pueden usarse de manera independiente o mixta:\nMenus graficos Comandos por voz Interaccion por gestos Uso de Herramientas Resultados # Conclusiones # Se puede evidenciar a simple vista las aplicaciones que tiene esta tecnologia a diversos campos, desde ciencias de la salud como aplicaciones en trabajos de ingenieria. Ademas que existe la posibilidad de adicionar mas campos de computacion visual, como lo puede ser el uso del Ray Tracing, para lograr un mejor resultado en la interaccion Humano-Maquina.\nTrabajo Futuro # Aplicar el uso de la camara para la seleccion del objeto y lograr mover la camara o enfoque que se tiene sobre este con el uso de las manos.\nRealizar una mejora de los efectos de luz, por ejemplo, mediante el uso del Ray Tracing o Ray Casting.\nReferencias # [1] https://en.wikipedia.org/wiki/3D_user_interaction\n"},{"id":1,"href":"/showcase/docs/entrega2/softwareRendering/","title":"Software Rendering","section":"Segunda Entrega","content":" Software Rendering # ¿Que es? # El Renderizado es el proceso de generacion de una imagen, ya sea en 2d o 3d, a partir de un modelo dado. Ahora el Renderizado por Software es realizar estos procesos mediante el uso de un software de la computadora, que no depende de un hardware de graficos (GPU) y se realiza unicamente en la CPU.\nLa principal diferencia entre renderizar en CPU y GPU es la velocidad en la que logran completar los procesos de la tarea, donde la segunda puede realizar mucho mas rapido estas tareas, dado que la GPU cuenta con mas nucleos, ademas de estar optimizada para graficos como para programacion paralela.\nstate-of-the-art (En que estado se encuentra el software rendering) # DirectX # Este es un conjunto de componentes , creados por Microsoft para los equipos que tengan Windows, que le permite al software funcionar directamente con el hardware de vídeo y audio, con el fin de mejorar la experiencia multimedia, principalmente en videojuegos. Actualmente se encuentra en la version 12, lanzada al mercado en el año 2022.\nNeural Rendering # Un efeciente renderizado de un mundo virtual foto realista es bastante complejo para los graficos generados por computadora, problema que si es solucionado podria hacer que estos graficos sean mas accesibles. Hoy en dia se encuentran avances en computacion visual y aprendizaje de maquina que buscan superar este reto, con los \u0026ldquo;Modelos generativos profundos\u0026rdquo; (Deep Generative Models).\nEl Renderizado Neural (Neural Rendering) es un nuevo campo que combina tecnicas del aprendizaje de maquina con la computacion grafica, integrando diferentes algoritmos de renderizado para entrenar una red neuronal.\nThe Mesa 3D Graphics Library # La libreria Mesa es una implementacion en software de codigo abierto de OpenGL, Vulkan y otras API de graficos. Esta libreria convierte sus especificaciones a los controladores de hardware especificos de cada proveedor, como lo son Intel o AMD que son los principales usuarios.\nLa libreria tambien contiene una implementacion para el renderizado por software conocida como swrast que permite el uso de shaders en la CPU para realizar Render Offline cuando no se cuenta con una GPU.\nTipos # Al momento de renderizar, podemos encontrar 2 categorias principales en las que se realiza este proceso:\n1. Real Time # El Renderizado en tiempo real (tambien conocido como Real Time) suele ser empleado para gráficos interactivos o videojuegos, donde las imágenes deben computarse con información 3D y visualizarse lo mas rapido posible.\n2. Pre-Rendering # El Pre-Renderizado (tambien conocido como Render Offline) se utiliza principalmente cuando la velocidad no es el factor mas importante. Este proceso de renderizado se encuentra con mayor frecuencia en proyectos de animación y efectos que requieren una mayor complejidad visual y recursos fotorrealistas a un nivel superior.\nTecnicas de renderizado en 3D # Rasterización: Para la representación de objetos 3D a tiempo real. Empleado para los gráficos interactivos. Se utiliza cuando no podemos sacrificar velocidad. En este caso, en lugar de de representar una imagen por píxeles, la rasterización se basa en «polígono por polígono». Raytracing: Se trata de un cálculo algorítmico del color de cada píxel cuando se trazan uno o más rayos de luz desde la cámara principal. Con esta técnica se logra un mayor fotorrealismo. Por el contrario de la técnica anterior, es más lenta. Radiosidad: La función principal de esta técnica es simular de forma precisa el color de las superficies por la iluminación indirecta. Su característica principal son las sombras suaves y graduadas que se ven influidas por el color de superficies cercanas. Posibles aplicaciones # Bienes raices\nDiseño de interiores\nIndustria del entretenimiento\nIndustria manufacturera\nArquitectura\nCiencias de salud\nPublicidad\nReferencias # [1] https://en.wikipedia.org/wiki/Software_rendering\n[2] https://www.gamedev.net/forums/topic/703265-state-of-art-in-real-time-software-rendering/\n[3] https://www.researchgate.net/publication/342905137_State_of_the_Art_on_Neural_Rendering\n[4] https://support.microsoft.com/es-es/topic/c%C3%B3mo-instalar-la-versi%C3%B3n-m%C3%A1s-reciente-de-directx-d1f5ffa5-dae2-246c-91b1-ee1e973ed8c2\n[5] https://3dalia.com/que-es-el-renderizado-3d/#Tipos_de_renderizado\n"},{"id":2,"href":"/showcase/docs/machBand/","title":"Mach Band","section":"Docs","content":" Bandas de Mach # Introduccion # Se realiza un generador de terrenos con el uso de Ruido de Perlin, buscando asemejar un mapa topografico que cambia de color segun la altura. Ademas se busca implementar el color con bandas de Mach, para suavisar el cambio de altura o color del mapa.\nContexto # Los colores se pueden interpretar de la siguiente manera\nBlanco = La mayor altura Rojo = Una altura media alta Amarillo = Una altura intermedia Verde = La altura mas baja Azul = Donde hay agua Resultados # Conclusiones y trabajo futuro # Se evidencia que se genero de manera correcta el terreno sin embargo no se logro aplicar de manera correcta el suavizado del color al terreno.\nA continuacion se busca mejorar el color y buscar que se logre suavizar de manera correcta.\n"},{"id":3,"href":"/showcase/docs/shadersEntrega/proceduralTexturing/","title":"Procedural Texturing","section":"Tercera Entrega","content":" 3D User Interaction # "},{"id":4,"href":"/showcase/docs/shadersEntrega/texturing/","title":"Texturing","section":"Tercera Entrega","content":" Texturing # UV Channel Blue # El mapeo UV o \u0026ldquo;UV mapping\u0026rdquo; es un proceso de modelacion 3D donde se hace una proyeccion de una imagen en 2d a la superficie de un modelo 3d. Las letras U y V hacen referencia a los ejes de la textura 2D, dado que las referencias X, Y y Z se usan para denotar los ejes en 3D, ademas que W se usa para calcular las rotaciones quaternarias, una operacion comun en computacion grafica.\nEl proceso de mapeo UV se basa en asignar pixeles en una imagen a los mapeos de la superficie en el polígono, normamente se hace copiando triangulos de la imagen mapeada y pegando estos triangulos en el objeto.\nAca se puede evidenciar el mismo proceso, pero esta vez partiendo desde un circulo.\nColoring Brightness Tools # Los modelos HSL y HSV son representaciones alternas del modelo RGB, diseñadas en 1970 por investigadores en computacion grafica para acercarse mas con la forma en que se persiben los seres humanos la vision de los colores.\nHSV value V # HSL lightness L # Component average # Trabajo Futuro # Lograr aplicar el mapeo de texturas UV en un entorno 3D, montando esto en un objeto y que se muestre con los colores que se establecieron en el shader.\nEn el caso del Luma, aplicar estos a videos y a otro tipo de imagenes a color, no solo aplicando una escala de grises, sino tambien hacer uso de estos con otra escala de colores y valores, como podria ser una imagen con negativos.\nReferencias # [1] https://en.wikipedia.org/wiki/UV_mapping\n[2] https://en.wikipedia.org/wiki/HSL_and_HSV\n"}]